{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ORIGINALCODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from absl import app, flags\n",
    "from absl.flags import FLAGS\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from models.common import DetectMultiBackend, AutoShape\n",
    "\n",
    "# Define command line flags\n",
    "flags.DEFINE_string('video', './data/test.mp4', 'Path to input video or webcam index (0)')\n",
    "flags.DEFINE_string('output', './output/output.mp4', 'path to output video')\n",
    "flags.DEFINE_float('conf', 0.75, 'confidence threshold')\n",
    "flags.DEFINE_integer('blur_id', None, 'class ID to apply Gaussian Blur')\n",
    "flags.DEFINE_integer('class_id', 0, 'class ID to track')\n",
    "\n",
    "def main(_argv):\n",
    "  # Initialize the video capture\n",
    "  video_input = FLAGS.video\n",
    "  # Check if the video input is an integer (webcam index)\n",
    "  if FLAGS.video.isdigit():\n",
    "      video_input = int(video_input)\n",
    "      cap = cv2.VideoCapture(video_input)\n",
    "  else:\n",
    "      cap = cv2.VideoCapture(video_input)\n",
    "  if not cap.isOpened():\n",
    "      print('Error: Unable to open video source.')\n",
    "      return\n",
    "  frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "  frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "  fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "  # video writer objects\n",
    "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "  writer = cv2.VideoWriter(FLAGS.output, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "  # Initialize the DeepSort tracker\n",
    "  tracker = DeepSort(max_age=50)\n",
    "  # select device (CPU or GPU)\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "  # Load YOLO model\n",
    "  model = DetectMultiBackend(weights='./weights/yolov9-e.pt',device=device, fuse=True)\n",
    "  model = AutoShape(model)\n",
    "\n",
    "  # Load the COCO class labels\n",
    "  classes_path = \"../configs/coco.names\"\n",
    "  with open(classes_path, \"r\") as f:\n",
    "      class_names = f.read().strip().split(\"\\n\")\n",
    "\n",
    "  # Create a list of random colors to represent each class\n",
    "  np.random.seed(42)\n",
    "  colors = np.random.randint(0, 255, size=(len(class_names), 3)) \n",
    "\n",
    "  while True:\n",
    "      ret, frame = cap.read()\n",
    "      if not ret:\n",
    "          break\n",
    "      # Run model on each frame\n",
    "      results = model(frame)\n",
    "      detect = []\n",
    "      for det in results.pred[0]:\n",
    "          label, confidence, bbox = det[5], det[4], det[:4]\n",
    "          x1, y1, x2, y2 = map(int, bbox)\n",
    "          class_id = int(label)\n",
    "\n",
    "          # Filter out weak detections by confidence threshold and class_id\n",
    "          if FLAGS.class_id is None:\n",
    "              if confidence < FLAGS.conf:\n",
    "                  continue\n",
    "          else:\n",
    "              if class_id != FLAGS.class_id or confidence < FLAGS.conf:\n",
    "                  continue\n",
    "\n",
    "          detect.append([[x1, y1, x2 - x1, y2 - y1], confidence, class_id])\n",
    "\n",
    "      tracks = tracker.update_tracks(detect, frame=frame)\n",
    "\n",
    "      for track in tracks:\n",
    "          if not track.is_confirmed():\n",
    "              continue\n",
    "          track_id = track.track_id\n",
    "          ltrb = track.to_ltrb()\n",
    "          class_id = track.get_det_class()\n",
    "          x1, y1, x2, y2 = map(int, ltrb)\n",
    "          color = colors[class_id]\n",
    "          B, G, R = map(int, color)\n",
    "          text = f\"{track_id} - {class_names[class_id]}\"\n",
    "\n",
    "          cv2.rectangle(frame, (x1, y1), (x2, y2), (B, G, R), 2)\n",
    "          cv2.rectangle(frame, (x1 - 1, y1 - 20), (x1 + len(text) * 12, y1), (B, G, R), -1)\n",
    "          cv2.putText(frame, text, (x1 + 5, y1 - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "          # Apply Gaussian Blur\n",
    "          if FLAGS.blur_id is not None and class_id == FLAGS.blur_id:\n",
    "              if 0 <= x1 < x2 <= frame.shape[1] and 0 <= y1 < y2 <= frame.shape[0]:\n",
    "                  frame[y1:y2, x1:x2] = cv2.GaussianBlur(frame[y1:y2, x1:x2], (99, 99), 3)\n",
    "\n",
    "      cv2.imshow('YOLOv9 Object tracking', frame)\n",
    "      writer.write(frame)\n",
    "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "          break\n",
    "\n",
    "  # Release video capture and writer\n",
    "  cap.release()\n",
    "  writer.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  try:\n",
    "      app.run(main)\n",
    "  except SystemExit:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHATGPT VERSION OF ORIGINAL CODE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Only detecting and tracking and line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from models.common import DetectMultiBackend, AutoShape\n",
    "\n",
    "# Configurations\n",
    "VIDEO_PATH = './data/test2.mp4'  # Path to input video or webcam index (0)\n",
    "OUTPUT_PATH = './output/output.mp4'  # Path to save the processed video\n",
    "YOLO_WEIGHTS = './weights/yolov9-e.pt'  # Path to YOLO model weights\n",
    "COCO_CLASSES_PATH = '../configs/coco.names'  # Path to class labels\n",
    "CONFIDENCE_THRESHOLD = 0.5  # Confidence threshold for detections\n",
    "BLUR_PEOPLE = False  # Set True to blur detected people (class ID 0)\n",
    "\n",
    "def main():\n",
    "    # Initialize video input\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open video source.\")\n",
    "        return\n",
    "    \n",
    "    # Video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Video writer for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Load YOLO model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = DetectMultiBackend(weights=YOLO_WEIGHTS, device=device, fuse=True)\n",
    "    model = AutoShape(model)\n",
    "\n",
    "    # Load COCO class labels\n",
    "    with open(COCO_CLASSES_PATH, 'r') as f:\n",
    "        class_names = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "    # Generate random color for \"person\" class (ID 0)\n",
    "    person_color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "\n",
    "    # Initialize DeepSort tracker\n",
    "    tracker = DeepSort(max_age=50)\n",
    "    \n",
    "    # Define the coordinates for the line (adjust these values later)\n",
    "    LINE_START = (450, 225) #450, 300 --> (yeh left side se uper neeche hota he - greater number = lower line) \n",
    "    LINE_END = (1000, 100)    \n",
    "    LINE_COLOR = (0, 0, 255)  # Red color\n",
    "    LINE_THICKNESS = 2       # Thickness of the line\n",
    "        \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Draw the line on the frame\n",
    "        cv2.line(frame, LINE_START, LINE_END, LINE_COLOR, LINE_THICKNESS)\n",
    "        \n",
    "        # Run YOLO model on the frame\n",
    "        results = model(frame)\n",
    "        detections = results.xyxy[0]  # YOLO detections as (x1, y1, x2, y2, conf, class_id)\n",
    "\n",
    "        detect = []\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2, confidence, class_id = map(float, det)\n",
    "            class_id = int(class_id)\n",
    "            \n",
    "            # Filter detections for \"person\" class (ID 0) and confidence threshold\n",
    "            if class_id == 0 and confidence >= CONFIDENCE_THRESHOLD:\n",
    "                detect.append([[x1, y1, x2 - x1, y2 - y1], confidence, class_id])\n",
    "        \n",
    "        # Update tracks with detections\n",
    "        tracks = tracker.update_tracks(detect, frame=frame)\n",
    "        \n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            \n",
    "            # Extract tracking details\n",
    "            track_id = track.track_id\n",
    "            x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), person_color, 2)\n",
    "            label = f\"ID {track_id}\"\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, person_color, 2)\n",
    "            \n",
    "            # Apply blur if enabled\n",
    "            if BLUR_PEOPLE:\n",
    "                frame[y1:y2, x1:x2] = cv2.GaussianBlur(frame[y1:y2, x1:x2], (99, 99), 30)\n",
    "        \n",
    "        # Show and save the frame\n",
    "        cv2.imshow('Person Tracking', frame)\n",
    "        writer.write(frame)\n",
    "            \n",
    "        # Quit on 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Detecting, tracking and counting those who enters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from models.common import DetectMultiBackend, AutoShape\n",
    "\n",
    "# Configurations\n",
    "VIDEO_PATH = './data/test2.mp4'  # Path to input video or webcam index (0)\n",
    "OUTPUT_PATH = './output/output.mp4'  # Path to save the processed video\n",
    "YOLO_WEIGHTS = './weights/yolov9-e.pt'  # Path to YOLO model weights\n",
    "COCO_CLASSES_PATH = '../configs/coco.names'  # Path to class labels\n",
    "CONFIDENCE_THRESHOLD = 0.5  # Confidence threshold for detections\n",
    "BLUR_PEOPLE = False  # Set True to blur detected people (class ID 0)\n",
    "\n",
    "def main():\n",
    "    # Initialize video input\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open video source.\")\n",
    "        return\n",
    "    \n",
    "    # Video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Video writer for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Load YOLO model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = DetectMultiBackend(weights=YOLO_WEIGHTS, device=device, fuse=True)\n",
    "    model = AutoShape(model)\n",
    "\n",
    "    # Load COCO class labels\n",
    "    with open(COCO_CLASSES_PATH, 'r') as f:\n",
    "        class_names = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "    # Generate random color for \"person\" class (ID 0)\n",
    "    person_color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "\n",
    "    # Initialize DeepSort tracker\n",
    "    tracker = DeepSort(max_age=50)\n",
    "    \n",
    "    # Define the coordinates for the line\n",
    "    LINE_START = (450, 225)\n",
    "    LINE_END = (1000, 100)\n",
    "    LINE_COLOR = (0, 0, 255)  # Red color\n",
    "    LINE_THICKNESS = 2  # Thickness of the line\n",
    "\n",
    "    # Initialize counter and store crossed IDs\n",
    "    people_count = 0\n",
    "    crossed_ids = set()\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Draw the line on the frame\n",
    "        cv2.line(frame, LINE_START, LINE_END, LINE_COLOR, LINE_THICKNESS)\n",
    "        \n",
    "        # Run YOLO model on the frame\n",
    "        results = model(frame)\n",
    "        detections = results.xyxy[0]  # YOLO detections as (x1, y1, x2, y2, conf, class_id)\n",
    "\n",
    "        detect = []\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2, confidence, class_id = map(float, det)\n",
    "            class_id = int(class_id)\n",
    "            \n",
    "            # Filter detections for \"person\" class (ID 0) and confidence threshold\n",
    "            if class_id == 0 and confidence >= CONFIDENCE_THRESHOLD:\n",
    "                detect.append([[x1, y1, x2 - x1, y2 - y1], confidence, class_id])\n",
    "        \n",
    "        # Update tracks with detections\n",
    "        tracks = tracker.update_tracks(detect, frame=frame)\n",
    "        \n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            \n",
    "            # Extract tracking details\n",
    "            track_id = track.track_id\n",
    "            x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), person_color, 2)\n",
    "            label = f\"ID {track_id}\"\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, person_color, 2)\n",
    "            \n",
    "            # Check if person crosses the line\n",
    "            center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "            if track_id not in crossed_ids:\n",
    "                # Line crossing check\n",
    "                if center_y < LINE_START[1] and center_y > LINE_END[1]:\n",
    "                    crossed_ids.add(track_id)\n",
    "                    people_count += 1\n",
    "        \n",
    "            # Apply blur if enabled\n",
    "            if BLUR_PEOPLE:\n",
    "                frame[y1:y2, x1:x2] = cv2.GaussianBlur(frame[y1:y2, x1:x2], (99, 99), 30)\n",
    "        \n",
    "        # Display the count on the frame\n",
    "        cv2.putText(frame, f\"People Count: {people_count}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Show and save the frame\n",
    "        cv2.imshow('Person Tracking', frame)\n",
    "        writer.write(frame)\n",
    "        \n",
    "        # Quit on 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Optimized Detecting, tracking and counting those who enters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from models.common import DetectMultiBackend, AutoShape\n",
    "import math\n",
    "\n",
    "# Configurations\n",
    "VIDEO_PATH =  0 #\"./data/test2.mp4\" # Path to input video or webcam index (0)\n",
    "OUTPUT_PATH = './output/output.mp4'  # Path to save the processed video\n",
    "YOLO_WEIGHTS = 'C:/Users/musha/Downloads/Yolo9-DeepSort-main/Yolo9-DeepSort-main/yolov9-c.pt'  # Path to YOLO model weights\n",
    "COCO_CLASSES_PATH = '../configs/coco.names'  # Path to class labels\n",
    "CONFIDENCE_THRESHOLD = 0.45  # Confidence threshold for detections\n",
    "BLUR_PEOPLE = False  # Set True to blur detected people (class ID 0)\n",
    "\n",
    "def main():\n",
    "    # Initialize video input\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open video source.\")\n",
    "        return\n",
    "    \n",
    "    # Video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Video writer for output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    # Load YOLO model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = DetectMultiBackend(weights=YOLO_WEIGHTS, device=device, fuse=True)\n",
    "    model = AutoShape(model)\n",
    "\n",
    "    # Load COCO class labels\n",
    "    with open(COCO_CLASSES_PATH, 'r') as f:\n",
    "        class_names = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "    # Generate random color for \"person\" class (ID 0)\n",
    "    person_color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "\n",
    "    # Initialize DeepSort tracker\n",
    "    tracker = DeepSort(\n",
    "        max_iou_distance=0.8,\n",
    "        max_age=10,\n",
    "        n_init=3,\n",
    "        nms_max_overlap=0.5,\n",
    "        max_cosine_distance=0.35,\n",
    "        nn_budget=100)\n",
    "    \n",
    "    # Define the coordinates for the line\n",
    "    LINE_START = (450, 275)\n",
    "    LINE_END = (600, 150) # (600,100) for optimal performance\n",
    "    LINE_COLOR = (0, 0, 255)  # Red color\n",
    "    LINE_THICKNESS = 2  # Thickness of the line\n",
    "\n",
    "    # Define frame skip\n",
    "    frame_skip = 6\n",
    "\n",
    "    # Initialize counter and store crossed IDs\n",
    "    people_count = 0\n",
    "    crossed_ids = set()\n",
    "    \n",
    "    frame_no = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_no+=1\n",
    "        if frame_no % frame_skip == 0:\n",
    "            \n",
    "            \n",
    "            # Draw the line on the frame\n",
    "            cv2.line(frame, LINE_START, LINE_END, LINE_COLOR, LINE_THICKNESS)\n",
    "            \n",
    "            # Run YOLO model on the frame\n",
    "            results = model(frame)\n",
    "            detections = results.xyxy[0]  # YOLO detections as (x1, y1, x2, y2, conf, class_id)\n",
    "\n",
    "            detect = []\n",
    "            for det in detections:\n",
    "                x1, y1, x2, y2, confidence, class_id = map(float, det)\n",
    "                class_id = int(class_id)\n",
    "                \n",
    "                # Filter detections for \"person\" class (ID 0) and confidence threshold\n",
    "                if class_id == 0 and confidence >= CONFIDENCE_THRESHOLD:\n",
    "                    detect.append([[x1, y1, x2 - x1, y2 - y1], confidence, class_id])\n",
    "            \n",
    "            # Update tracks with detections\n",
    "            tracks = tracker.update_tracks(detect, frame=frame)\n",
    "            \n",
    "            for track in tracks:\n",
    "                \n",
    "                if int(track.track_id) >= 3:\n",
    "                    print(\"mean\",track.track_id)\n",
    "                    print(track.mean[4],track.mean[5])\n",
    "                if not track.is_confirmed():\n",
    "                    continue\n",
    "                \n",
    "                # Extract tracking details\n",
    "                track_id = track.track_id\n",
    "                x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
    "                \n",
    "                # Draw bounding box and label\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), person_color, 2)\n",
    "                label = f\"ID {track_id}\"\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, person_color, 2)\n",
    "                \n",
    "                if track_id not in crossed_ids:\n",
    "                    center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "                    # Calculate A, B, C for the line equation\n",
    "                    A = LINE_END[1] - LINE_START[1]\n",
    "                    B = LINE_START[0] - LINE_END[0]\n",
    "                    C = LINE_END[0] * LINE_START[1] - LINE_START[0] * LINE_END[1]\n",
    "\n",
    "                    # Compute the distance\n",
    "                    distance = (A * center_x + B * center_y + C) / math.sqrt(A**2 + B**2)\n",
    "                    if distance > 0 and abs(distance) < 50 and track.mean[4] > 0.0:\n",
    "                        \n",
    "                        crossed_ids.add(track_id)\n",
    "                        people_count += 1\n",
    "                \n",
    "            \n",
    "                # Apply blur if enabled\n",
    "                if BLUR_PEOPLE:\n",
    "                    frame[y1:y2, x1:x2] = cv2.GaussianBlur(frame[y1:y2, x1:x2], (99, 99), 30)\n",
    "            \n",
    "            # Display the count on the frame\n",
    "            cv2.putText(frame, f\"People Count: {people_count}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # Show and save the frame\n",
    "            cv2.imshow('Person Tracking', frame)\n",
    "            writer.write(frame)\n",
    "            \n",
    "            # Quit on 'q' key\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "    # Cleanup\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
